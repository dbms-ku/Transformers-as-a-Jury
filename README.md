# Transformers-as-a-Jury (TaaJ)
Transformers-as-a-Jury: Mimicking LLM-as-a-Judge Text Evaluation on Edge Devices
[![Python](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/)  
[![PyTorch](https://img.shields.io/badge/pytorch-2.x-red.svg)](https://pytorch.org/)  
[![Edge AI](https://img.shields.io/badge/edge-AI-green.svg)]()  
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

## Overview

The **Transformers-as-a-Jury (TaaJ)** project provides a lightweight, on-device alternative to **LLM-as-a-Judge** systems.  
Instead of relying on large, cloud-hosted models for automated text evaluation, TaaJ leverages compact transformer architectures fine-tuned on **LLM-labeled datasets** to enable **local, low-latency, and privacy-preserving text evaluation**.

This approach is particularly suited for **edge deployments** where bandwidth, compute power, and energy are constrained.  

ğŸš€ **Key innovation**: TaaJ mimics the evaluation capabilities of cloud-based judges while running efficiently on devices such as the **Raspberry Pi 5**.

---

## Features

- âš¡ **On-device evaluation**: Run locally without cloud calls.  
- ğŸ” **LLM-mimicking scoring**: Compact transformers replicate the judgment of large LLMs.  
- ğŸŒ± **Agricultural use case demo**: Evaluate generated farm advisory text on a Raspberry Pi 5.  
- ğŸ”’ **Privacy-first**: Keeps all text and evaluation on-device.  
- ğŸ›  **Open-source PyTorch & Ollama integration**: Easy to extend and adapt.  

---

## Methodology
Domain-agnostic 5-step methodology for TaaJ.

```text
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚  Step 1: On-device Text Gen â”‚
 â”‚  â€¢ Prompts + IoT (Sobol)    â”‚
 â”‚  â€¢ Compact Ollama Models    â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚  Step 2: Dataset Labelling  â”‚
 â”‚  â€¢ Candidate Texts          â”‚
 â”‚  â€¢ LLM-as-a-Judge (70B)     â”‚
 â”‚  â€¢ Criteria: clarity, etc.  â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ Step 3: Training of TaaJ    â”‚
 â”‚  â€¢ DistilBERT per criterion â”‚
 â”‚  â€¢ Weighted focal loss       â”‚
 â”‚  â€¢ Early stopping            â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ Step 4: Deployment          â”‚
 â”‚  â€¢ Transfer to RPi 5        â”‚
 â”‚  â€¢ Memory-fit optimization  â”‚
 â”‚  â€¢ Ollama runtime ready     â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ Step 5: System Testing      â”‚
 â”‚  â€¢ Evaluate new texts       â”‚
 â”‚  â€¢ Compare with LLM-Judge   â”‚
 â”‚  â€¢ Regenerate if < thresholdâ”‚
 â”‚  â€¢ Collect metrics          â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Installation
```bash
git clone https://github.com/<your-username>/taaj.git
cd taaj
pip install -r requirements.txt
```
